# 2025Tpami
2025Tpami：代码开源，整体思路解析

## 工作过程问题总结（逐步整理更新）
（1）：基础视觉语言大模型对Office-Caltech跨域数据集的强大影响

动机：实验过程中，通过分配客户端组给Office-Caltech实现数据异质，对比2024cvpr&2023cvpr，3214客户端组划分策略，每个客户端抽取该域数据集0.2的数据量，引入clip作为backbond（对比resnet10）fedavg聚合效果98%，采取更极端划分，只分配0.01数据量，发现结果还是很高，修改客户端组为1111，数据量0.01，各个数据域划分数据为1，训练效果仍然很高

推测原因：

  1:训练集和测试集图像之间极度相似，即使在少样本情况下，仍可以使训练效果极好（clip特征相似度高） 
  
  2:类间差异性大，即使clip下文本图像相似度不太高，图片与图片之间相似度不高，但是十个类之间很好区分。
  
后面可以补充一个小实验，对Office-Caltech的四个数据集分别进行clip测试，具体实验：拿一个数据集举例，首先是十个类各取一张图片，作为训练图片参照，然后拿一张训练图片参照与十个类各随机抽的一张图片，一共十张图片做相似度计算，可以证明即使样本只有一个，分类效果也很好

（2）：clip backbond下分类任务数量的探究

动机：在工作中我们发现在clip作为backbond的情况下，对多个跨域数据集（digits、Office-Caltech、pacs）进行特征提取，参照2024cvpr&2023cvpr&2024Tpami的设置，联邦（Fedavg）架构下精度高达97%，我们进行了更极端的训练划分，多round收敛后仍然能达到95%，最极端情况下，我们设置各个域只被一个客户端划分，各个客户端的各个类只划分一个样本，联邦聚合后精度仍有90%
基于此现象，我们希望对当前多个主流联邦架构，进行clip+联邦架构的性能分析，分析传统设置，少样本设置，零样本设置分析

推测原因：

 1:诸如clip、dino v2这样的视觉语言基础大模型，在面临多分类任务场景，表现出60-70较低的精度，在对于十分类cifar-10、少分类跨域数据集而言，表现出较高的精度，得益于clip图像解码器的相似度分析，由于训练clip的策略是对比学习，开放学习，持续学习，导致clip对于万物都有一定的识别，直观的就是对于Office-Caltech的随便一张bike图片，使用文本图片相似度、图片余弦相似度分析，都能取得不低的效果，这种效果在少分类问题，尤其是类间差异大的情况下将会被进一步放大
 
 2:跨域数据集中虽然提出了跨域，但是不同域的相同类仍然具有较大的相似性和一致性，特别的就是Office-Caltech的样本

 据此我们希望在实验后，提出少分类跨域问题将被诸如clip这样的大模型解决，我们将进一步研究多分类跨域问题

